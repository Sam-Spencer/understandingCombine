#title "Buffer"

# <%= title %>

`.buffer` accumulates values from upstream into its internal buffer, which is of predefined size, until the buffer fills up due to backpressure from downstream. At that point, it throws away values from upstream or throws an error, depending on how you've configured the operator. The buffer itself effectively behaves as a FIFO stack (also known as a queue).

Some examples will clarify, but first let's talk about the parameters:

`size:`
: The size of the buffer.

`prefetch:`
: The strategy for requesting values from upstream. There are two possibilities:

  * `.keepFull` means that the operator should immediately request enough values to cause the buffer to overflow. 
  
  * `.byRequest`, despite the name, means that the operator should immediately request an unlimited number of values.

`whenFull:`
: The policy to be followed when a value arrives from upstream but the buffer is full. There are three possibilities:

  * `.dropNewest` means throw away the new value that doesn't fit into the buffer. 
  
  * `.dropOldest` means throw away the first value from the buffer and append the new value at the end.
  
  * `.customError` takes an associated value that's a function producing an Error, which is sent downstream as a failure.

To make sense of `.buffer`, we need a pipeline that exerts backpressure from below. Here's one:

    let pub = Timer.publish(every: 0.2, on: .main, in: .common).autoconnect()
        .scan(0) {i,_ in i+1}
        .buffer(size: 4, prefetch: .byRequest, whenFull: .dropNewest)
        .flatMap(maxPublishers:.max(1)) {
            Just($0).delay(for: 2, scheduler: DispatchQueue.main)

At the top of the pipeline we have a publisher that produces values every one-fifth of a second. At the bottom we have a `.flatMap` with a `.max(1)` demand setting, so that it asks for just one value at a time, while transforming its received values into publishers with a two-second `.delay`. This means that when a value arrives into the `.flatMap`, it sits there for two seconds before being published, at which point the `.flatMap` requests a new value.

If there were no `.buffer` operator in the story, this pipeline would simply produce one successive Int every two seconds. The backpressure from `.flatMap` applies directly to the publisher at the top: every time the `.flatMap` asks for a new value, the upstream produces the next value in the series. But now we have introduced a buffer between them — and the buffer can hold only four values at a time. What will happen? Here's what we get, one value ever two seconds, at the end of the pipeline:

    RESULT: 1
    RESULT: 2
    RESULT: 3
    RESULT: 4
    RESULT: 5
    RESULT: 12
    RESULT: 23
    RESULT: 33
    ...

The `.flatMap` starts by asking for a value, and after one-fifth of a second, it gets it. The `1` is now sitting in the `.flatMap`, waiting for two seconds to be published, exerting backpressure on the buffer. Meanwhile values keep arriving into the buffer: the `2`, the `3`, the `4`, the `5`... But now the buffer is full (because it only holds four values), and the `6` arrives. That's an overflow. We have told the buffer that `.dropNewest`, so the `6` is thrown away. And so on for the `7`, the `8`, and all the numbers until the `.flatMap` publishes the `1` and asks for a new value. At the point, the buffer feeds it the `2`, freeing up a space in the buffer. So when the `12` arrives, there's room for it, and in it goes into the buffer. Now there's no more room again, while we wait two seconds for the `.flatMap` to clear, and the `13` arrives and is thrown away, then the `14`, and so on. Eventually we reach a steady state where only every 10th or 11th value from the top of pipeline arrives at the bottom; all the others are being thrown away because they encounter a full buffer.

If we change `.dropNewest` to `.dropOldest`, the result is the same except that we achieve the steady state much sooner:

    RESULT: 1
    RESULT: 9
    RESULT: 19
    RESULT: 30
    RESULT: 40
    RESULT: 50
    RESULT: 61
    RESULT: 71
    ...

As before, the `1` passes into the `.flatMap` and the `2`, `3`, `4`, and `5` fill up the buffer. But now when the `6` arrives it goes into the buffer and the `2` is thrown away; the `7` arrives and goes into the buffer and the `3` is thrown away; and so on. Eventually the buffer consists of `9`, `10`, `11`, `12` — and at that moment the `1` is finally published from the `.flatMap`, which requests a new value, and is handed the `9` from the start of the buffer.

So much for the `.byRequest` strategy. Now let's switch to the `.keepFull` strategy:

    .buffer(size: 4, prefetch: .keepFull, whenFull: .dropNewest)

Here's what we get:

    RESULT: 1
    RESULT: 2
    RESULT: 3
    RESULT: 4
    RESULT: 5
    RESULT: 7
    RESULT: 9
    ...

The buffer now follows a policy where it keeps asking for values _until there's an overflow._ When that happens, the buffer _stops_ asking for values until the buffer has an open slot. So the `1` passes through to the `.flatMap` and sits there, exerting backpressure. Meanwhile the `2`, `3`, `4` and `5` arrive and fill the buffer. The `6` arrives and causes an overflow; the `6` is thrown away and the buffer _stops_ asking for values. Eventually the `.flatMap` publishes the `1` and receives the `2` from the buffer, opening a slot in the buffer. At the point the buffer receives the `7` and puts it in the buffer, and receives the `8`. That's an overflow, so the `8` is thrown away and the buffer _stops_ asking for values. And so on.

Finally, if we change `.dropNewest` to `.dropOldest`, the pipeline produces `1`, `3`, `5`, `7`, and so on, for reasons that should now be obvious.

